{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from mistralai import Mistral\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('MISTRAL_API_KEY')\n",
    "\n",
    "if api_key and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'mistral-small-latest'\n",
    "client=Mistral(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# following is the function to aswer technical Question\n",
    "def answer_question(question):\n",
    "    response=client.chat.complete(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            { \"role\" : \"system\" , \"content\" : \"You are helpful AI to answer technical questions related to LLMS\" },\n",
    "            { \"role\" : \"user\" , \"content\" : question }\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mastering LLM (Large Language Model) engineering involves a combination of understanding the underlying principles, gaining practical experience, and staying updated with the latest research. Here's a roadmap to help you:\n",
      "\n",
      "1. **Build a Strong Foundation:**\n",
      "   - **Mathematics:** Strengthen your understanding of linear algebra, probability, statistics, and calculus, as they form the backbone of machine learning and deep learning.\n",
      "   - **Programming:** Be proficient in Python, as it's the most widely used language in the field. Familiarize yourself with libraries like NumPy, Pandas, and PyTorch/TensorFlow.\n",
      "   - **Machine Learning:** Understand the basics of machine learning, including supervised and unsupervised learning, model evaluation, and feature engineering.\n",
      "\n",
      "2. **Understand Natural Language Processing (NLP):**\n",
      "   - Learn about text preprocessing, word embeddings (Word2Vec, GloVe), and traditional NLP models like RNNs, LSTMs, and GRUs.\n",
      "   - Study attention mechanisms and transformer architectures, which are crucial for understanding LLMs.\n",
      "\n",
      "3. **Learn About Large Language Models:**\n",
      "   - Study the architecture of popular LLMs like BERT, RoBERTa, T5, and their variants.\n",
      "   - Understand the concept of self-supervised learning and how it's applied to pre-train these models.\n",
      "   - Learn about fine-tuning techniques for downstream tasks.\n",
      "\n",
      "4. **Hands-On Practice:**\n",
      "   - Implement and fine-tune LLMs on smaller datasets using libraries like Hugging Face's Transformers.\n",
      "   - Participate in NLP challenges and competitions on platforms like Kaggle to gain practical experience.\n",
      "   - Contribute to open-source projects related to LLMs.\n",
      "\n",
      "5. **Stay Updated with Research:**\n",
      "   - Regularly read research papers on arXiv and other platforms to stay updated with the latest developments.\n",
      "   - Follow blogs and newsletters from organizations like Hugging Face, Google AI, and OpenAI.\n",
      "   - Attend conferences and webinars on NLP and LLMs.\n",
      "\n",
      "6. **Learn About Deployment and Scalability:**\n",
      "   - Understand how to deploy LLMs in production environments.\n",
      "   - Learn about model optimization techniques to make them more efficient and scalable.\n",
      "\n",
      "7. **Join the Community:**\n",
      "   - Engage with the NLP and LLM community on platforms like GitHub, Reddit, and specialized forums.\n",
      "   - Ask questions, share your work, and learn from others.\n",
      "\n",
      "8. **Specialize (Optional):**\n",
      "   - Once you're comfortable with the basics, you can specialize in areas like multilingual LLMs, low-resource NLP, or ethical considerations in LLMs.\n",
      "\n",
      "9. **Patience and Persistence:**\n",
      "   - Mastering LLM engineering takes time and consistent effort. Don't be discouraged by setbacks. Keep learning and practicing.\n",
      "\n",
      "10. **Ethical Considerations:**\n",
      "    - Familiarize yourself with the ethical implications of LLMs, including bias, fairness, and privacy concerns. Strive to build models that are responsible and beneficial to society.\n",
      "\n",
      "Resources:\n",
      "- Hugging Face's Transformers course\n",
      "- Stanford's CS224N: Natural Language Processing with Deep Learning\n",
      "- Deep Learning for NLP by Oxford University\n",
      "- arXiv Sanity Preserver for staying updated with research\n",
      "- NLP subreddit and other online communities\n"
     ]
    }
   ],
   "source": [
    "print(answer_question(\"How I can Master LLM Engineering?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
